# -*- coding: utf-8 -*-
"""SWN_Annotation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18yUrCSDxgdSDNpiy4rsm2uNxU1dkCLK2
"""

!pip install googletrans==4.0.0-rc1
!pip install microsofttranslator

import pandas as pd
import nltk
from nltk.corpus import sentiwordnet as swn
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag
from googletrans import Translator

# Download NLTK resources
nltk.download('punkt')
nltk.download('sentiwordnet')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

def calculate_tweet_sentiment(tweet_content):
    pos_score = 0
    neg_score = 0

    words = word_tokenize(tweet_content)
    lemmatizer = WordNetLemmatizer()

    for word, pos in pos_tag(words):
        wordnet_tag = get_wordnet_pos(pos)
        wordnet_synsets = list(swn.senti_synsets(lemmatizer.lemmatize(word), wordnet_tag))
        if wordnet_synsets:
            synset = wordnet_synsets[0]
            pos_score += synset.pos_score()
            neg_score += synset.neg_score()

    sentiment_score = pos_score - neg_score
    return sentiment_score  # Returning the sentiment score itself

def get_wordnet_pos(treebank_tag):
    if treebank_tag.startswith('J'):
        return 'a'  # Adjective
    elif treebank_tag.startswith('V'):
        return 'v'  # Verb
    elif treebank_tag.startswith('N'):
        return 'n'  # Noun
    elif treebank_tag.startswith('R'):
        return 'r'  # Adverb
    else:
        return None


# Load your dataset (replace 'your_dataset.xlsx' with your file path)
file_path = '/content/September 2023 PB.xlsx'  # Replace this with your file path
df = pd.read_excel(file_path)


# Preprocessing and translation of the 'Comments' column
translator = Translator()

def preprocess_translate(comment):
    comment = comment.lower()
    comment = ''.join([c for c in comment if c.isalpha() or c.isspace()])
    if comment.strip().lower() == comment:  # Check if the comment is in English
        return comment  # Skip translation for English comments
    try:
        translated = translator.translate(comment, src='auto', dest='en').text
        return translated
    except Exception as e:
        print(f"Translation error: {e}")
        return comment  # Return the original text if translation fails

# Apply preprocessing and translation to 'Comments' column
df['Translated_Comments'] = df['Comments'].apply(preprocess_translate)

# Extract POS tags for each comment
def get_pos_tags(comment):
    words = word_tokenize(comment)
    return pos_tag(words)

df['POS_Tags'] = df['Translated_Comments'].apply(get_pos_tags)
# Add a new column 'POS_Tags' containing the POS tags for each comment

# Apply sentiment analysis to the translated comments
df['Senti_Score'] = df['Translated_Comments'].apply(calculate_tweet_sentiment)

# Apply labels based on sentiment score using SentiWordNet scores
def get_sentiment_label(score):
    pos_threshold = 0.25
    neg_threshold = -0.25

    if score > pos_threshold:
        return 'strongly positive'
    elif score > 0 and score <= pos_threshold:
        return 'weakly positive'
    elif score < neg_threshold:
        return 'strongly negative'
    elif score >= 0 and score < neg_threshold:
        return 'weakly negative'
    else:
        return 'neutral'

df['Labels'] = df['Senti_Score'].apply(get_sentiment_label)
# Add a new column 'Labels' containing the sentiment labels based on scores

# Display the modified DataFrame
print(df.head())

# Extracting filename from the file path
file_name = file_path.split('/')[-1]  # Extracting only the filename from the path

# Add 'Updated_' prefix to the filename
updated_file_name = '/content/Updated_' + file_name

# Save the updated DataFrame to a new Excel file
df.to_excel(updated_file_name, index=False)

"""#-------------------------------------------------------------------------------------------------------------------------

#Use This Section if you face any error in the translating the Comments column
"""

import pandas as pd
import nltk
from nltk.corpus import sentiwordnet as swn
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag
from googletrans import Translator

# Download NLTK resources
nltk.download('punkt')
nltk.download('sentiwordnet')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

def calculate_tweet_sentiment(tweet_content):
    pos_score = 0
    neg_score = 0

    words = word_tokenize(tweet_content)
    lemmatizer = WordNetLemmatizer()

    for word, pos in pos_tag(words):
        wordnet_tag = get_wordnet_pos(pos)
        wordnet_synsets = list(swn.senti_synsets(lemmatizer.lemmatize(word), wordnet_tag))
        if wordnet_synsets:
            synset = wordnet_synsets[0]
            pos_score += synset.pos_score()
            neg_score += synset.neg_score()

    sentiment_score = pos_score - neg_score
    return sentiment_score  # Returning the sentiment score itself

def get_wordnet_pos(treebank_tag):
    if treebank_tag.startswith('J'):
        return 'a'  # Adjective
    elif treebank_tag.startswith('V'):
        return 'v'  # Verb
    elif treebank_tag.startswith('N'):
        return 'n'  # Noun
    elif treebank_tag.startswith('R'):
        return 'r'  # Adverb
    else:
        return None


# Load your dataset (replace 'your_dataset.xlsx' with your file path)
file_path = '/content/Jan 2023 PF.xlsx'  # Replace this with your file path
df = pd.read_excel(file_path)


# Preprocessing and translation of the 'Comments' column
translator = Translator()

def preprocess_translate(comment):
    if isinstance(comment, str):  # Check if the comment is a string
        comment = comment.lower()
        comment = ''.join([c for c in comment if c.isalpha() or c.isspace()])
        if comment.strip().lower() == comment:  # Check if the comment is in English
            return comment  # Skip translation for English comments
        try:
            translated = translator.translate(comment, src='ur', dest='en').text  # Translate from Urdu to English
            return translated
        except Exception as e:
            print(f"Translation error: {e}")
            return comment  # Return the original text if translation fails
    else:
        return str(comment)  # Convert non-string data to string


# Apply preprocessing and translation to 'Comments' column
df['Translated_Comments'] = df['Comments'].apply(preprocess_translate)

# Extract POS tags for each comment
def get_pos_tags(comment):
    words = word_tokenize(comment)
    return pos_tag(words)

df['POS_Tags'] = df['Translated_Comments'].apply(get_pos_tags)
# Add a new column 'POS_Tags' containing the POS tags for each comment

# Apply sentiment analysis to the translated comments
df['Senti_Score'] = df['Translated_Comments'].apply(calculate_tweet_sentiment)

# Apply labels based on sentiment score using SentiWordNet scores
def get_sentiment_label(score):
    pos_threshold = 0.25
    neg_threshold = -0.25

    if score > pos_threshold:
        return 'strongly positive'
    elif score > 0 and score <= pos_threshold:
        return 'weakly positive'
    elif score < neg_threshold:
        return 'strongly negative'
    elif score >= 0 and score < neg_threshold:
        return 'weakly negative'
    else:
        return 'neutral'

df['Labels'] = df['Senti_Score'].apply(get_sentiment_label)
# Add a new column 'Labels' containing the sentiment labels based on scores

# Display the modified DataFrame
print(df.head())

# Extracting filename from the file path
file_name = file_path.split('/')[-1]  # Extracting only the filename from the path

# Add 'Updated_' prefix to the filename
updated_file_name = '/content/Updated_' + file_name

# Save the updated DataFrame to a new Excel file
df.to_excel(updated_file_name, index=False)

"""#Microsoft Translator"""

import pandas as pd
from microsofttranslator import Translator
import nltk
from nltk.corpus import sentiwordnet as swn
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag

# Download NLTK resources
nltk.download('punkt')
nltk.download('sentiwordnet')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

def calculate_tweet_sentiment(tweet_content):
    pos_score = 0
    neg_score = 0

    words = word_tokenize(tweet_content)
    lemmatizer = WordNetLemmatizer()

    for word, pos in pos_tag(words):
        wordnet_tag = get_wordnet_pos(pos)
        wordnet_synsets = list(swn.senti_synsets(lemmatizer.lemmatize(word), wordnet_tag))
        if wordnet_synsets:
            synset = wordnet_synsets[0]
            pos_score += synset.pos_score()
            neg_score += synset.neg_score()

    sentiment_score = pos_score - neg_score
    return sentiment_score  # Returning the sentiment score itself

def get_wordnet_pos(treebank_tag):
    if treebank_tag.startswith('J'):
        return 'a'  # Adjective
    elif treebank_tag.startswith('V'):
        return 'v'  # Verb
    elif treebank_tag.startswith('N'):
        return 'n'  # Noun
    elif treebank_tag.startswith('R'):
        return 'r'  # Adverb
    else:
        return None


# Load your dataset (replace 'your_dataset.xlsx' with your file path)
file_path = '/content/September 2023 JB.xlsx'  # Replace this with your file path
df = pd.read_excel(file_path)

# Initialize the Microsoft Translator
translator = Translator('YOUR_CLIENT_ID', 'YOUR_CLIENT_SECRET')

# Define the translation function
def preprocess_translate(comment):
    if isinstance(comment, str):  # Check if the comment is a string
        comment = comment.lower()
        comment = ''.join([c for c in comment if c.isalpha() or c.isspace()])
        if comment.strip().lower() == comment:  # Check if the comment is in English
            return comment  # Skip translation for English comments
        try:
            translated = translator.translate(comment, lang_from='auto', lang_to='en')
            return translated
        except Exception as e:
            print(f"Translation error: {e}")
            return comment  # Return the original text if translation fails
    else:
        return str(comment)  # Convert non-string data to string


# Apply preprocessing and translation to 'Comments' column
df['Translated_Comments'] = df['Comments'].apply(preprocess_translate)

# Extract POS tags for each comment
def get_pos_tags(comment):
    words = word_tokenize(comment)
    return pos_tag(words)

df['POS_Tags'] = df['Translated_Comments'].apply(get_pos_tags)
# Add a new column 'POS_Tags' containing the POS tags for each comment

# Apply sentiment analysis to the translated comments
df['Senti_Score'] = df['Translated_Comments'].apply(calculate_tweet_sentiment)

# Apply labels based on sentiment score using SentiWordNet scores
def get_sentiment_label(score):
    pos_threshold = 0.25
    neg_threshold = -0.25

    if score > pos_threshold:
        return 'strongly positive'
    elif score > 0 and score <= pos_threshold:
        return 'weakly positive'
    elif score < neg_threshold:
        return 'strongly negative'
    elif score >= 0 and score < neg_threshold:
        return 'weakly negative'
    else:
        return 'neutral'

df['Labels'] = df['Senti_Score'].apply(get_sentiment_label)
# Add a new column 'Labels' containing the sentiment labels based on scores

# Display the modified DataFrame
print(df.head())

# Extracting filename from the file path
file_name = file_path.split('/')[-1]  # Extracting only the filename from the path

# Add 'Updated_' prefix to the filename
updated_file_name = '/content/Updated_' + file_name

# Save the updated DataFrame to a new Excel file
df.to_excel(updated_file_name, index=False)

"""#DeepL Tansalator

"""

import pandas as pd
import nltk
from nltk.corpus import sentiwordnet as swn
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag
import requests

# Download NLTK resources
nltk.download('punkt')
nltk.download('sentiwordnet')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

# Function to perform translation using DeepL API
def deepl_translate(text, api_key):
    url = "https://api.deepl.com/v2/translate"
    params = {
        'auth_key': api_key,
        'text': text,
        'target_lang': 'EN'
    }
    response = requests.post(url, data=params)
    if response.status_code == 200:
        return response.json()['translations'][0]['text']
    else:
        print(f"Translation error: {response.status_code}")
        return text

# Function to preprocess and translate comments
def preprocess_translate(comment):
    if isinstance(comment, str):
        comment = comment.lower()
        comment = ''.join([c for c in comment if c.isalpha() or c.isspace()])
        if comment.strip().lower() == comment:
            return comment
        try:
            translated = deepl_translate(comment, 'YOUR_API_KEY')
            return translated
        except Exception as e:
            print(f"Translation error: {e}")
            return comment
    else:
        return str(comment)

# Function to calculate sentiment score
def calculate_tweet_sentiment(tweet_content):
    pos_score = 0
    neg_score = 0

    words = word_tokenize(tweet_content)
    lemmatizer = WordNetLemmatizer()

    for word, pos in pos_tag(words):
        wordnet_tag = get_wordnet_pos(pos)
        wordnet_synsets = list(swn.senti_synsets(lemmatizer.lemmatize(word), wordnet_tag))
        if wordnet_synsets:
            synset = wordnet_synsets[0]
            pos_score += synset.pos_score()
            neg_score += synset.neg_score()

    sentiment_score = pos_score - neg_score
    return sentiment_score

# Function to get WordNet POS tags
def get_wordnet_pos(treebank_tag):
    if treebank_tag.startswith('J'):
        return 'a'
    elif treebank_tag.startswith('V'):
        return 'v'
    elif treebank_tag.startswith('N'):
        return 'n'
    elif treebank_tag.startswith('R'):
        return 'r'
    else:
        return None

# Load your dataset
file_path = '/content/September 2023 JB.xlsx'  # Replace with your file path
df = pd.read_excel(file_path)

# Apply preprocessing and translation to 'Comments' column
df['Translated_Comments'] = df['Comments'].apply(preprocess_translate)

# Apply sentiment analysis to the translated comments
df['Senti_Score'] = df['Translated_Comments'].apply(calculate_tweet_sentiment)

# Apply labels based on sentiment score using SentiWordNet scores
def get_sentiment_label(score):
    pos_threshold = 0.25
    neg_threshold = -0.25

    if score > pos_threshold:
        return 'strongly positive'
    elif score > 0 and score <= pos_threshold:
        return 'weakly positive'
    elif score < neg_threshold:
        return 'strongly negative'
    elif score >= 0 and score < neg_threshold:
        return 'weakly negative'
    else:
        return 'neutral'

df['Labels'] = df['Senti_Score'].apply(get_sentiment_label)

# Display the modified DataFrame
print(df.head())

# Extracting filename from the file path
file_name = file_path.split('/')[-1]
updated_file_name = '/content/Updated_' + file_name

# Save the updated DataFrame to a new Excel file
df.to_excel(updated_file_name, index=False)